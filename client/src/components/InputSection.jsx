// src/components/InputSection.jsx
import React, { useState, useRef, useEffect } from 'react';
import { getAuth } from 'firebase/auth';
import { db } from '../firebase';
import { collection, addDoc, serverTimestamp } from 'firebase/firestore';
import { getGeminiReply } from '../services/geminiApi';
import { franc } from 'franc';

function InputSection({ onReply }) {
  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА state тФАтФАтФАтФАтФАтФАтФАтФАтФА */
  const [input, setInput]           = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [inputMethod, setInputMethod] = useState(null);

  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА refs тФАтФАтФАтФАтФАтФАтФАтФАтФАтФА */
  const silenceTimerRef   = useRef(null);
  const recognitionRef    = useRef(null);
  const speechSynthesisRef = useRef(null);

  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА user / lang тФАтФАтФА */
  const user     = getAuth().currentUser;
  const userLang = localStorage.getItem('lang') || 'en-IN';

  /* тФАтФАтФАтФАтФАтФАтФА voice setup тФАтФАтФАтФАтФА */
  useEffect(() => {
    speechSynthesisRef.current = window.speechSynthesis;
    const populate = () => speechSynthesisRef.current?.getVoices();
    speechSynthesisRef.current.addEventListener('voiceschanged', populate);
    return () => {
      speechSynthesisRef.current.removeEventListener('voiceschanged', populate);
      speechSynthesisRef.current.cancel();
    };
  }, []);

  /* тФАтФАтФАтФАтФАтФАтФА cleanup тФАтФАтФАтФАтФАтФАтФАтФАтФА */
  useEffect(() => {
    return () => {
      clearTimeout(silenceTimerRef.current);
      recognitionRef.current?.stop();
      speechSynthesisRef.current?.cancel();
    };
  }, []);

  /* тФАтФАтФАтФАтФА TTS helper тФАтФАтФАтФАтФАтФАтФАтФА */
  const speak = (text, lang) => {
    const synth = speechSynthesisRef.current;
    if (!synth) return;
    synth.cancel();
    const uttr    = new SpeechSynthesisUtterance(text);
    uttr.lang     = lang;
    uttr.rate     = 1.0;
    uttr.pitch    = 1.0;
    const voices  = synth.getVoices();
    const voice   =
      voices.find(v => v.lang === lang) ||
      voices.find(v => v.lang.startsWith(lang.split('-')[0])) ||
      voices[0];
    uttr.voice = voice;
    setTimeout(() => synth.speak(uttr), 100);
  };

  /* тФАтФАтФАтФАтФА language detect тФАтФАтФА */
  const detectLanguage = (text) => {
    if (text.length < 3) return userLang;
    const map = {
      hin: 'hi-IN', tel: 'te-IN', tam: 'ta-IN', kan: 'kn-IN',
      eng: 'en-IN', mar: 'mr-IN', ben: 'bn-IN', guj: 'gu-IN',
      mal: 'ml-IN', pan: 'pa-IN', urd: 'ur-IN'
    };
    const code = franc(text, { minLength: 3, only: Object.keys(map) });
    return map[code] || userLang;
  };

  /* тФАтФАтФАтФАтФА start / stop SR тФАтФАтФА */
  const stopListening = () => {
    clearTimeout(silenceTimerRef.current);
    recognitionRef.current?.stop();
    setIsListening(false);
  };

  const startListening = () => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) return alert('Speech Recognition not supported in this browser');
    recognitionRef.current                  = new SR();
    recognitionRef.current.lang             = userLang;
    recognitionRef.current.interimResults   = true;
    recognitionRef.current.continuous       = true;
    recognitionRef.current.maxAlternatives  = 1;

    const resetSilence = () => {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = setTimeout(stopListening, 3000);
    };

    recognitionRef.current.onresult = (e) => {
      resetSilence();
      const transcript = Array.from(e.results).map(r => r[0].transcript).join('');
      if (e.results[e.results.length - 1].isFinal) {
        setInputMethod('speech');
        handleSubmit(transcript, detectLanguage(transcript));
      }
    };
    recognitionRef.current.onerror = (err) => { console.error(err); stopListening(); };
    recognitionRef.current.onend   = () => { setIsListening(false); setIsProcessing(false); };

    setIsListening(true);
    recognitionRef.current.start();
    resetSilence();
  };

  /* тФАтФАтФАтФАтФА handle submit тФАтФАтФАтФАтФА */
  const handleSubmit = async (textVal, forcedLang) => {
    const finalInput = textVal || input.trim();
    if (!finalInput) return;

    setIsProcessing(true);
    try {
      const responseLang = forcedLang || detectLanguage(finalInput);
      const langCode     = responseLang.slice(0,2);

      /* ---------- NEW EMOTIONAL PROMPT ---------- */
      const prompt = `
You are a wise, emotionally strong Indian woman (like an elder sister or trusted midwife).
Give a short, warm, and deeply empathetic reply in ${langCode}.
if user mentions any symptoms related to health, give suggestions accordingly. keep in mind that the user is either in pregnancy or prepreganncy or post pregnancy.
тАв 2тАС3 concise lines
тАв Gentle reassurance, emotional support
тАв A dash of motivation or cultural wisdom if fitting
User said:
"${finalInput}"`;

      const reply = await getGeminiReply(prompt, langCode);

      /* update UI */
      onReply(reply, responseLang, inputMethod || 'text');
      speak(reply, responseLang);
      setInput('');
      setInputMethod(null);

      /* store entry */
      if (user) {
        console.log('ЁЯУж Saving entry for UID:', user.uid);
        await addDoc(collection(db, 'users', user.uid, 'entries'), {
          input: finalInput,
          response: reply,
          lang: responseLang,
          inputMethod: inputMethod || 'text',
          createdAt: serverTimestamp()
        });
      } else console.warn('тЪая╕П No authenticated user, skipping Firestore write');
    } catch (err) {
      console.error('Gemini error', err);
      const fallback = userLang.startsWith('hi')
        ? 'рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдЕрднреА рдЙрддреНрддрд░ рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред'
        : 'Sorry, IтАЩm unable to respond right now. Please try again.';
      onReply(fallback, userLang, inputMethod || 'text');
      speak(fallback, userLang);
    } finally {
      setIsProcessing(false);
    }
  };

  /* тФАтФАтФАтФАтФА text submit click тФА */
  const handleTextSubmit = () => { setInputMethod('text'); handleSubmit(); };

  /* тФАтФАтФАтФАтФА translations тФАтФАтФАтФАтФАтФА */
  const translations = {
    'hi-IN': { ph:'рдЬрдирдиреА рд╕реЗ рдмрд╛рдд рдХрд░реЗрдВ...', send:'рднреЗрдЬреЗрдВ', mic:'рдмреЛрд▓реЗрдВ' },
    'te-IN': { ph:"р░Ьр░ир░ир░┐р░др▒Л р░ор░╛р░Яр▒Нр░▓р░╛р░бр░Вр░бр░┐..."
, send:'р░кр░Вр░кр▒Б', mic:'р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Б' },
    'ta-IN': { ph:"роЬройройро┐ропрпБроЯройрпН рокрпЗроЪрпБроЩрпНроХро│рпН..."
, send:'роЕройрпБрокрпНрокрпБ', mic:'рокрпЗроЪ' },
    'kn-IN': { ph:"р▓Ьр▓ир▓ир▓┐р▓пр│Кр▓Вр▓жр▓┐р▓Чр│Ж р▓ор▓╛р▓др▓ир▓╛р▓бр▓┐..."
, send:'р▓Хр▓│р│Бр▓╣р│Ж', mic:'р▓ор▓╛р▓др▓ир▓╛р▓бр▓┐' },
    'mr-IN': { ph:"рдЬрдирдиреАрд╕реЛрдмрдд рдмреЛрд▓рд╛..."
, send:'рдкрд╛рдард╡рд╛', mic:'рдмреЛрд▓рд╛' },
    'bn-IN': { ph:"ржЬржиржирж┐рж░ рж╕ржЩрзНржЧрзЗ ржХржерж╛ ржмрж▓рзБржи..."
, send:'ржкрж╛ржарж╛ржи', mic:'ржмрж▓рзБржи' },
    'gu-IN': { ph:"ркЬркиркирлА рк╕рк╛ркерлЗ рк╡рк╛ркд ркХрк░рлЛ..."
, send:'ркорлЛркХрк▓рлЛ', mic:'ркмрлЛрк▓рлЛ' },
    'ml-IN': { ph:"р┤Ьр┤ир┤ир┤┐р┤пр╡Бр┤ор┤╛р┤пр┤┐ р┤╕р┤Вр┤╕р┤╛р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤Х..."
, send:' р┤Ер┤пр┤пр╡Нр┤Хр╡Нр┤Хр╡Бр┤Х', mic:'р┤╕р┤Вр┤╕р┤╛р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤Х' },
    'pa-IN': { ph:"риЬриириирйА риири╛ри▓ риЧрй▒ри▓ риХри░рйЛ..."
, send:'ринрйЗриЬрйЛ', mic:'римрйЛри▓рйЛ' },
    'ur-IN': { ph:'╪з┘╛┘Ж╪з ╪│┘И╪з┘Д ┘Д┌й┌╛█М┌║...', send:'╪и┌╛█М╪м█М┌║', mic:'╪и┘И┘Д█М┌║' },
    default : { ph:'Talk to Janani...', send:'Send', mic:'Speak' }
  };
  const t = translations[userLang] || translations.default;
  const { ph:placeholder, send, mic:speakLabel } = t;

  /* тФАтФАтФАтФАтФА render тФАтФАтФАтФАтФА */
  return (
    <div className="p-4 bg-white shadow rounded-xl w-full max-w-2xl">
      <div className="flex items-center gap-2">
        <input
          type="text"
          placeholder={placeholder}
          value={input}
          onChange={e => setInput(e.target.value)}
          onKeyDown={e => e.key === 'Enter' && handleTextSubmit()}
          className="flex-1 border p-2 rounded-lg"
          disabled={isProcessing}
        />
        <button
          onClick={handleTextSubmit}
          disabled={isProcessing}
          className="px-4 py-2 rounded-lg bg-pink-500 text-white hover:bg-pink-600 disabled:opacity-50"
        >
          {isProcessing ? '...' : send}
        </button>
        <button
          onClick={isListening ? stopListening : startListening}
          disabled={isProcessing}
          className={`px-4 py-2 rounded-lg bg-pink-500 text-white hover:bg-pink-600 disabled:opacity-50 ${
            isListening ? 'bg-red-500 text-white' : 'bg-gray-100'
          } disabled:opacity-50`}
          title={speakLabel}
        >
          {isProcessing ? '...' : 'ЁЯОЩя╕П'}
        </button>
      </div>
    </div>
  );
}

export default InputSection;
