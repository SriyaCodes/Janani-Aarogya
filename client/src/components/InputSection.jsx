// src/components/InputSection.jsx
import React, { useState, useRef, useEffect } from 'react';
import { getAuth } from 'firebase/auth';
import { db } from '../firebase';
import { collection, addDoc, serverTimestamp } from 'firebase/firestore';
import { getGeminiReply } from '../services/geminiApi';
import { franc } from 'franc';

function InputSection({ onReply }) {
  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА state тФАтФАтФАтФАтФАтФАтФАтФАтФА */
  const [input, setInput]           = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [inputMethod, setInputMethod] = useState(null);
  const [availableVoices, setAvailableVoices] = useState([]);

  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА refs тФАтФАтФАтФАтФАтФАтФАтФАтФАтФА */
  const silenceTimerRef   = useRef(null);
  const recognitionRef    = useRef(null);
  const speechSynthesisRef = useRef(null);

  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА user / lang тФАтФАтФА */
  const user     = getAuth().currentUser;
  const userLang = localStorage.getItem('lang') || 'en-IN';

  /* тФАтФАтФАтФАтФАтФАтФА voice setup тФАтФАтФАтФАтФА */
  useEffect(() => {
    speechSynthesisRef.current = window.speechSynthesis;
    
    const populateVoices = () => {
      const voices = speechSynthesisRef.current?.getVoices() || [];
      setAvailableVoices(voices);
      console.log('Available voices:', voices.map(v => `${v.name} (${v.lang})`));
    };
    
    // Load voices immediately if available
    populateVoices();
    
    // Listen for voice changes
    speechSynthesisRef.current.addEventListener('voiceschanged', populateVoices);
    
    return () => {
      speechSynthesisRef.current.removeEventListener('voiceschanged', populateVoices);
      speechSynthesisRef.current.cancel();
    };
  }, []);

  /* тФАтФАтФАтФАтФАтФАтФА cleanup тФАтФАтФАтФАтФАтФАтФАтФАтФА */
  useEffect(() => {
    return () => {
      clearTimeout(silenceTimerRef.current);
      recognitionRef.current?.stop();
      speechSynthesisRef.current?.cancel();
    };
  }, []);

  /* тФАтФАтФАтФАтФА Enhanced voice selection тФАтФАтФАтФАтФАтФАтФАтФА */
  const selectBestVoice = (targetLang) => {
    if (!availableVoices.length) return null;

    // Define preferred voice names for each language (native accents)
    const preferredVoices = {
      'hi-IN': ['Google рд╣рд┐рдиреНрджреА', 'Microsoft Kalpana', 'Lekha', 'Neel', 'Shreya'],
      'te-IN': ['Google р░др▒Жр░▓р▒Бр░Чр▒Б', 'Microsoft Heera', 'Chitra'],
      'ta-IN': ['Google родрооро┐ро┤рпН', 'Microsoft Valluvar', 'Karthik'],
      'kn-IN': ['Google р▓Хр▓ир│Нр▓ир▓б', 'Microsoft Suma'],
      'mr-IN': ['Google рдорд░рд╛рдареА', 'Microsoft Omkar'],
      'bn-IN': ['Google ржмрж╛ржВрж▓рж╛', 'Microsoft Sushmita', 'Bashkar'],
      'gu-IN': ['Google ркЧрлБркЬрк░рк╛ркдрлА', 'Microsoft Gujarati'],
      'ml-IN': ['Google р┤ор┤▓р┤пр┤╛р┤│р┤В', 'Microsoft Malayalam'],
      'pa-IN': ['Google рикрй░риЬри╛римрйА', 'Microsoft Punjabi'],
      'ur-IN': ['Google ╪з╪▒╪п┘И', 'Microsoft Urdu'],
      'en-IN': ['Google English (India)', 'Microsoft Nandini', 'Ravi', 'Heera']
    };

    // Step 1: Try to find exact language match with preferred voices
    const langPreferred = preferredVoices[targetLang] || [];
    for (const prefName of langPreferred) {
      const voice = availableVoices.find(v => 
        v.name.includes(prefName) || 
        v.name.toLowerCase().includes(prefName.toLowerCase())
      );
      if (voice) {
        console.log(`тЬЕ Selected preferred voice: ${voice.name} for ${targetLang}`);
        return voice;
      }
    }

    // Step 2: Try exact language code match
    let exactMatch = availableVoices.find(v => v.lang === targetLang);
    if (exactMatch) {
      console.log(`тЬЕ Selected exact match: ${exactMatch.name} for ${targetLang}`);
      return exactMatch;
    }

    // Step 3: Try language family match (e.g., 'hi' for 'hi-IN')
    const baseLang = targetLang.split('-')[0];
    const familyMatch = availableVoices.find(v => v.lang.startsWith(baseLang));
    if (familyMatch) {
      console.log(`тЬЕ Selected family match: ${familyMatch.name} for ${targetLang}`);
      return familyMatch;
    }

    // Step 4: Try alternative regional codes
    const alternativeRegions = {
      'hi': ['hi-IN', 'hi'],
      'te': ['te-IN', 'te'],
      'ta': ['ta-IN', 'ta-LK', 'ta'],
      'kn': ['kn-IN', 'kn'],
      'mr': ['mr-IN', 'mr'],
      'bn': ['bn-IN', 'bn-BD', 'bn'],
      'gu': ['gu-IN', 'gu'],
      'ml': ['ml-IN', 'ml'],
      'pa': ['pa-IN', 'pa-PK', 'pa'],
      'ur': ['ur-IN', 'ur-PK', 'ur'],
      'en': ['en-IN', 'en-US', 'en-GB', 'en-AU', 'en']
    };

    const alternatives = alternativeRegions[baseLang] || [];
    for (const altLang of alternatives) {
      const altVoice = availableVoices.find(v => v.lang === altLang);
      if (altVoice) {
        console.log(`тЬЕ Selected alternative: ${altVoice.name} for ${targetLang}`);
        return altVoice;
      }
    }

    // Step 5: Fallback to English (India) or any English
    const enIndiaVoice = availableVoices.find(v => v.lang === 'en-IN');
    if (enIndiaVoice) {
      console.log(`тЪая╕П Fallback to English (India): ${enIndiaVoice.name}`);
      return enIndiaVoice;
    }

    const anyEnglish = availableVoices.find(v => v.lang.startsWith('en'));
    if (anyEnglish) {
      console.log(`тЪая╕П Fallback to English: ${anyEnglish.name}`);
      return anyEnglish;
    }

    // Step 6: Last resort - first available voice
    console.log(`тЪая╕П Last resort: ${availableVoices[0]?.name}`);
    return availableVoices[0] || null;
  };

  /* тФАтФАтФАтФАтФА Enhanced TTS helper тФАтФАтФАтФАтФАтФАтФАтФА */
  const speak = (text, lang) => {
    const synth = speechSynthesisRef.current;
    if (!synth || !text.trim()) return;
    
    // Cancel any ongoing speech
    synth.cancel();
    
    // Wait a moment for cancel to complete
    setTimeout(() => {
      const utterance = new SpeechSynthesisUtterance(text);
      
      // Set language
      utterance.lang = lang;
      
      // Configure speech parameters for better quality
      utterance.rate = 0.9;  // Slightly slower for clarity
      utterance.pitch = 1.0;
      utterance.volume = 1.0;
      
      // Select the best voice
      const selectedVoice = selectBestVoice(lang);
      if (selectedVoice) {
        utterance.voice = selectedVoice;
        console.log(`ЁЯОд Speaking with voice: ${selectedVoice.name} (${selectedVoice.lang})`);
      } else {
        console.warn('тЪая╕П No suitable voice found, using default');
      }
      
      // Add event listeners for debugging
      utterance.onstart = () => console.log('ЁЯО╡ Speech started');
      utterance.onend = () => console.log('ЁЯО╡ Speech ended');
      utterance.onerror = (e) => console.error('ЁЯЪл Speech error:', e);
      
      // Speak with additional delay to ensure proper voice loading
      setTimeout(() => {
        try {
          synth.speak(utterance);
        } catch (error) {
          console.error('Speech synthesis error:', error);
        }
      }, 100);
    }, 100);
  };

  /* тФАтФАтФАтФАтФА language detect тФАтФАтФА */
  const detectLanguage = (text) => {
    if (text.length < 3) return userLang;
    const map = {
      hin: 'hi-IN', tel: 'te-IN', tam: 'ta-IN', kan: 'kn-IN',
      eng: 'en-IN', mar: 'mr-IN', ben: 'bn-IN', guj: 'gu-IN',
      mal: 'ml-IN', pan: 'pa-IN', urd: 'ur-IN'
    };
    const code = franc(text, { minLength: 3, only: Object.keys(map) });
    return map[code] || userLang;
  };

  /* тФАтФАтФАтФАтФА start / stop SR тФАтФАтФА */
  const stopListening = () => {
    clearTimeout(silenceTimerRef.current);
    recognitionRef.current?.stop();
    setIsListening(false);
  };

  const startListening = () => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) return alert('Speech Recognition not supported in this browser');
    
    recognitionRef.current = new SR();
    recognitionRef.current.lang = userLang;
    recognitionRef.current.interimResults = true;
    recognitionRef.current.continuous = true;
    recognitionRef.current.maxAlternatives = 1;

    const resetSilence = () => {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = setTimeout(stopListening, 3000);
    };

    recognitionRef.current.onresult = (e) => {
      resetSilence();
      const transcript = Array.from(e.results).map(r => r[0].transcript).join('');
      if (e.results[e.results.length - 1].isFinal) {
        setInputMethod('speech');
        handleSubmit(transcript, detectLanguage(transcript));
      }
    };
    
    recognitionRef.current.onerror = (err) => { 
      console.error('Speech recognition error:', err); 
      stopListening(); 
    };
    
    recognitionRef.current.onend = () => { 
      setIsListening(false); 
      setIsProcessing(false); 
    };

    setIsListening(true);
    recognitionRef.current.start();
    resetSilence();
  };

  /* тФАтФАтФАтФАтФА handle submit тФАтФАтФАтФАтФА */
  const handleSubmit = async (textVal, forcedLang) => {
    const finalInput = textVal || input.trim();
    if (!finalInput) return;

    setIsProcessing(true);
    try {
      const responseLang = forcedLang || detectLanguage(finalInput);
      const langCode = responseLang.slice(0, 2);

      /* ---------- EMOTIONAL PROMPT ---------- */
      const prompt = `
You are a wise, emotionally strong Indian woman (like an elder sister or trusted midwife).
Give a short, warm, and deeply empathetic reply in ${langCode}.
if user mentions any symptoms related to health, give suggestions accordingly. keep in mind that the user is either in pregnancy or prepreganncy or post pregnancy.
тАв 2тАС3 concise lines
тАв Gentle reassurance, emotional support
тАв A dash of motivation or cultural wisdom if fitting
User said:
"${finalInput}"`;

      const reply = await getGeminiReply(prompt, langCode);

      /* update UI */
      onReply(reply, responseLang, inputMethod || 'text');
      
      /* speak with enhanced voice selection */
      speak(reply, responseLang);
      
      setInput('');
      setInputMethod(null);

      /* store entry */
      if (user) {
        console.log('ЁЯУж Saving entry for UID:', user.uid);
        await addDoc(collection(db, 'users', user.uid, 'entries'), {
          input: finalInput,
          response: reply,
          lang: responseLang,
          inputMethod: inputMethod || 'text',
          createdAt: serverTimestamp()
        });
      } else {
        console.warn('тЪая╕П No authenticated user, skipping Firestore write');
      }
    } catch (err) {
      console.error('Gemini error', err);
      const fallback = userLang.startsWith('hi')
        ? 'рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдЕрднреА рдЙрддреНрддрд░ рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред'
        : 'Sorry, Im unable to respond right now. Please try again.';
      onReply(fallback, userLang, inputMethod || 'text');
      speak(fallback, userLang);
    } finally {
      setIsProcessing(false);
    }
  };

  /* тФАтФАтФАтФАтФА text submit click тФА */
  const handleTextSubmit = () => { 
    setInputMethod('text'); 
    handleSubmit(); 
  };

  /* тФАтФАтФАтФАтФА translations тФАтФАтФАтФАтФАтФА */
  const translations = {
    'hi-IN': { ph:'рдЬрдирдиреА рд╕реЗ рдмрд╛рдд рдХрд░реЗрдВ...', send:'рднреЗрдЬреЗрдВ', mic:'рдмреЛрд▓реЗрдВ' },
    'te-IN': { ph:"р░Ьр░ир░ир░┐р░др▒Л р░ор░╛р░Яр▒Нр░▓р░╛р░бр░Вр░бр░┐...", send:'р░кр░Вр░кр▒Б', mic:'р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Б' },
    'ta-IN': { ph:"роЬройройро┐ропрпБроЯройрпН рокрпЗроЪрпБроЩрпНроХро│рпН...", send:'роЕройрпБрокрпНрокрпБ', mic:'рокрпЗроЪ' },
    'kn-IN': { ph:"р▓Ьр▓ир▓ир▓┐р▓пр│Кр▓Вр▓жр▓┐р▓Чр│Ж р▓ор▓╛р▓др▓ир▓╛р▓бр▓┐...", send:'р▓Хр▓│р│Бр▓╣р│Ж', mic:'р▓ор▓╛р▓др▓ир▓╛р▓бр▓┐' },
    'mr-IN': { ph:"рдЬрдирдиреАрд╕реЛрдмрдд рдмреЛрд▓рд╛...", send:'рдкрд╛рдард╡рд╛', mic:'рдмреЛрд▓рд╛' },
    'bn-IN': { ph:"ржЬржиржирж┐рж░ рж╕ржЩрзНржЧрзЗ ржХржерж╛ ржмрж▓рзБржи...", send:'ржкрж╛ржарж╛ржи', mic:'ржмрж▓рзБржи' },
    'gu-IN': { ph:"ркЬркиркирлА рк╕рк╛ркерлЗ рк╡рк╛ркд ркХрк░рлЛ...", send:'ркорлЛркХрк▓рлЛ', mic:'ркмрлЛрк▓рлЛ' },
    'ml-IN': { ph:"р┤Ьр┤ир┤ир┤┐р┤пр╡Бр┤ор┤╛р┤пр┤┐ р┤╕р┤Вр┤╕р┤╛р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤Х...", send:'р┤Ер┤пр┤пр╡Нр┤Хр╡Нр┤Хр╡Бр┤Х', mic:'р┤╕р┤Вр┤╕р┤╛р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤Х' },
    'pa-IN': { ph:"риЬриириирйА риири╛ри▓ риЧрй▒ри▓ риХри░рйЛ...", send:'ринрйЗриЬрйЛ', mic:'римрйЛри▓рйЛ' },
    'ur-IN': { ph:'╪з┘╛┘Ж╪з ╪│┘И╪з┘Д ┘Д┌й┌╛█М┌║...', send:'╪и┌╛█М╪м█М┌║', mic:'╪и┘И┘Д█М┌║' },
    default: { ph:'Talk to Janani...', send:'Send', mic:'Speak' }
  };
  
  const t = translations[userLang] || translations.default;
  const { ph: placeholder, send, mic: speakLabel } = t;

  /* тФАтФАтФАтФАтФА render тФАтФАтФАтФАтФА */
  return (
    <div className="p-4 bg-white shadow rounded-xl w-full max-w-2xl">
      <div className="flex items-center gap-2">
        <input
          type="text"
          placeholder={placeholder}
          value={input}
          onChange={e => setInput(e.target.value)}
          onKeyDown={e => e.key === 'Enter' && handleTextSubmit()}
          className="flex-1 border p-2 rounded-lg"
          disabled={isProcessing}
        />
        <button
          onClick={handleTextSubmit}
          disabled={isProcessing}
          className="px-4 py-2 rounded-lg bg-pink-500 text-white hover:bg-pink-600 disabled:opacity-50"
        >
          {isProcessing ? '...' : send}
        </button>
        <button
          onClick={isListening ? stopListening : startListening}
          disabled={isProcessing}
          className={`px-4 py-2 rounded-lg text-white hover:bg-pink-600 disabled:opacity-50 ${
            isListening ? 'bg-red-500' : 'bg-pink-500'
          }`}
          title={speakLabel}
        >
          {isProcessing ? '...' : 'ЁЯОЩя╕П'}
        </button>
      </div>
      
      {/* Debug info for development */}
      {process.env.NODE_ENV === 'development' && (
        <div className="mt-2 text-xs text-gray-500">
          Available voices: {availableVoices.length} | User lang: {userLang}
        </div>
      )}
    </div>
  );
}

export default InputSection;