// src/components/InputSection.jsx
import React, { useState, useRef, useEffect } from 'react';
import { getAuth } from 'firebase/auth';
import { db } from '../firebase';
import { collection, addDoc, serverTimestamp } from 'firebase/firestore';
import { getGeminiReply } from '../services/geminiApi';
import { franc } from 'franc';

function InputSection({ onReply }) {
  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА state тФАтФАтФАтФАтФАтФАтФАтФАтФА */
  const [input, setInput]           = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [inputMethod, setInputMethod] = useState(null);

  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА refs тФАтФАтФАтФАтФАтФАтФАтФАтФАтФА */
  const silenceTimerRef   = useRef(null);
  const recognitionRef    = useRef(null);
  const speechSynthesisRef = useRef(null);

  /* тФАтФАтФАтФАтФАтФАтФАтФАтФА user / lang тФАтФАтФА */
  const user     = getAuth().currentUser;
  const userLang = localStorage.getItem('lang') || 'en-IN';

  /* тФАтФАтФАтФАтФАтФАтФА voice setup тФАтФАтФАтФАтФА */
  useEffect(() => {
    speechSynthesisRef.current = window.speechSynthesis;
    const populate = () => speechSynthesisRef.current?.getVoices();
    speechSynthesisRef.current.addEventListener('voiceschanged', populate);
    return () => {
      speechSynthesisRef.current.removeEventListener('voiceschanged', populate);
      speechSynthesisRef.current.cancel();
    };
  }, []);

  /* тФАтФАтФАтФАтФАтФАтФА cleanup тФАтФАтФАтФАтФАтФАтФАтФАтФА */
  useEffect(() => {
    return () => {
      clearTimeout(silenceTimerRef.current);
      recognitionRef.current?.stop();
      speechSynthesisRef.current?.cancel();
    };
  }, []);

  /* тФАтФАтФАтФАтФА TTS helper тФАтФАтФАтФАтФАтФАтФАтФА */
  const speak = (text, lang) => {
    const synth = speechSynthesisRef.current;
    if (!synth) return;
    synth.cancel();
    const uttr    = new SpeechSynthesisUtterance(text);
    uttr.lang     = lang;
    uttr.rate     = 0.9;
    uttr.pitch    = 1.0;
    const voices  = synth.getVoices();
    const voice   =
      voices.find(v => v.lang === lang) ||
      voices.find(v => v.lang.startsWith(lang.split('-')[0])) ||
      voices[0];
    uttr.voice = voice;
    setTimeout(() => synth.speak(uttr), 100);
  };

  /* тФАтФАтФАтФАтФА language detect тФАтФАтФА */
  const detectLanguage = (text) => {
    if (text.length < 3) return userLang;
    const map = {
      hin: 'hi-IN', tel: 'te-IN', tam: 'ta-IN', kan: 'kn-IN',
      eng: 'en-IN', mar: 'mr-IN', ben: 'bn-IN', guj: 'gu-IN',
      mal: 'ml-IN', pan: 'pa-IN', urd: 'ur-IN'
    };
    const code = franc(text, { minLength: 3, only: Object.keys(map) });
    return map[code] || userLang;
  };

  /* тФАтФАтФАтФАтФА start / stop SR тФАтФАтФА */
  const stopListening = () => {
    clearTimeout(silenceTimerRef.current);
    recognitionRef.current?.stop();
    setIsListening(false);
  };

  const startListening = () => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) return alert('Speech Recognition not supported in this browser');
    recognitionRef.current                  = new SR();
    recognitionRef.current.lang             = userLang;
    recognitionRef.current.interimResults   = true;
    recognitionRef.current.continuous       = true;
    recognitionRef.current.maxAlternatives  = 1;

    const resetSilence = () => {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = setTimeout(stopListening, 3000);
    };

    recognitionRef.current.onresult = (e) => {
      resetSilence();
      const transcript = Array.from(e.results).map(r => r[0].transcript).join('');
      if (e.results[e.results.length - 1].isFinal) {
        setInputMethod('speech');
        handleSubmit(transcript, detectLanguage(transcript));
      }
    };
    recognitionRef.current.onerror = (err) => { console.error(err); stopListening(); };
    recognitionRef.current.onend   = () => { setIsListening(false); setIsProcessing(false); };

    setIsListening(true);
    recognitionRef.current.start();
    resetSilence();
  };

  /* тФАтФАтФАтФАтФА handle submit тФАтФАтФАтФАтФА */
  const handleSubmit = async (textVal, forcedLang) => {
    const finalInput = textVal || input.trim();
    if (!finalInput) return;

    setIsProcessing(true);
    try {
      const responseLang = forcedLang || detectLanguage(finalInput);
      const langCode     = responseLang.slice(0,2);

      /* ---------- NEW EMOTIONAL PROMPT ---------- */
      const prompt = `
You are a wise, emotionally strong Indian woman (like an elder sister or trusted midwife).
Give a short, warm, and deeply empathetic reply in ${langCode}.
if user mentions any symptoms related to health, give suggestions accordingly. keep in mind that the user is either in pregnancy or prepreganncy or post pregnancy.
тАв 2тАС3 concise lines
тАв Gentle reassurance, emotional support
тАв A dash of motivation or cultural wisdom if fitting
User said:
"${finalInput}"`;

      const reply = await getGeminiReply(prompt, langCode);

      /* update UI */
      onReply(reply, responseLang, inputMethod || 'text');
      speak(reply, responseLang);
      setInput('');
      setInputMethod(null);

      /* store entry */
      if (user) {
        console.log('ЁЯУж Saving entry for UID:', user.uid);
        await addDoc(collection(db, 'users', user.uid, 'entries'), {
          input: finalInput,
          response: reply,
          lang: responseLang,
          inputMethod: inputMethod || 'text',
          createdAt: serverTimestamp()
        });
      } else console.warn('тЪая╕П No authenticated user, skipping Firestore write');
    } catch (err) {
      console.error('Gemini error', err);
      const fallback = userLang.startsWith('hi')
        ? 'рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдЕрднреА рдЙрддреНрддрд░ рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред'
        : 'Sorry, IтАЩm unable to respond right now. Please try again.';
      onReply(fallback, userLang, inputMethod || 'text');
      speak(fallback, userLang);
    } finally {
      setIsProcessing(false);
    }
  };

  /* тФАтФАтФАтФАтФА text submit click тФА */
  const handleTextSubmit = () => { setInputMethod('text'); handleSubmit(); };

  /* тФАтФАтФАтФАтФА translations тФАтФАтФАтФАтФАтФА */
  const translations = {
    'hi-IN': { ph:'рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рд▓рд┐рдЦреЗрдВ...', send:'рднреЗрдЬреЗрдВ', mic:'рдмреЛрд▓реЗрдВ' },
    'te-IN': { ph:'р░ор▒А р░кр▒Нр░░р░╢р▒Нр░и р░Яр▒Ир░кр▒Н р░Ър▒Зр░пр░Вр░бр░┐...', send:'р░кр░Вр░кр▒Б', mic:'р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Б' },
    'ta-IN': { ph:'роЙроЩрпНроХро│рпН роХрпЗро│рпНро╡ро┐...', send:'роЕройрпБрокрпНрокрпБ', mic:'рокрпЗроЪ' },
    'kn-IN': { ph:'р▓ир▓┐р▓ор│Нр▓о р▓кр│Нр▓░р▓╢р│Нр▓ир│Ж...', send:'р▓Хр▓│р│Бр▓╣р│Ж', mic:'р▓ор▓╛р▓др▓ир▓╛р▓бр▓┐' },
    'mr-IN': { ph:'рддреБрдордЪрд╛ рдкреНрд░рд╢реНрди...', send:'рдкрд╛рдард╡рд╛', mic:'рдмреЛрд▓рд╛' },
    'bn-IN': { ph:'ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржи...', send:'ржкрж╛ржарж╛ржи', mic:'ржмрж▓рзБржи' },
    'gu-IN': { ph:'ркдркорк╛рк░рлЛ рккрлНрк░рк╢рлНрки...', send:'ркорлЛркХрк▓рлЛ', mic:'ркмрлЛрк▓рлЛ' },
    'ml-IN': { ph:'р┤Ър╡Лр┤жр╡Нр┤пр┤В р┤Яр╡Ир┤кр╡Нр┤кр╡Бр┤Ър╡Жр┤пр╡Нр┤пр╡В...', send:' р┤Ер┤пр┤пр╡Нр┤Хр╡Нр┤Хр╡Бр┤Х', mic:'р┤╕р┤Вр┤╕р┤╛р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤Х' },
    'pa-IN': { ph:'риЖрикригри╛ ри╕ри╡ри╛ри▓...', send:'ринрйЗриЬрйЛ', mic:'римрйЛри▓рйЛ' },
    'ur-IN': { ph:'╪з┘╛┘Ж╪з ╪│┘И╪з┘Д ┘Д┌й┌╛█М┌║...', send:'╪и┌╛█М╪м█М┌║', mic:'╪и┘И┘Д█М┌║' },
    default : { ph:'Type your question...', send:'Send', mic:'Speak' }
  };
  const t = translations[userLang] || translations.default;
  const { ph:placeholder, send, mic:speakLabel } = t;

  /* тФАтФАтФАтФАтФА render тФАтФАтФАтФАтФА */
  return (
    <div className="p-4 bg-white shadow rounded-xl w-full max-w-2xl">
      <div className="flex items-center gap-2">
        <input
          type="text"
          placeholder={placeholder}
          value={input}
          onChange={e => setInput(e.target.value)}
          onKeyDown={e => e.key === 'Enter' && handleTextSubmit()}
          className="flex-1 border p-2 rounded-lg"
          disabled={isProcessing}
        />
        <button
          onClick={handleTextSubmit}
          disabled={isProcessing}
          className="px-4 py-2 rounded-lg bg-pink-500 text-white hover:bg-pink-600 disabled:opacity-50"
        >
          {isProcessing ? '...' : send}
        </button>
        <button
          onClick={isListening ? stopListening : startListening}
          disabled={isProcessing}
          className={`px-4 py-2 rounded-full border ${
            isListening ? 'bg-red-500 text-white' : 'bg-gray-100'
          } disabled:opacity-50`}
          title={speakLabel}
        >
          {isProcessing ? '...' : 'ЁЯОд'}
        </button>
      </div>
    </div>
  );
}

export default InputSection;
